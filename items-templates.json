[
    {
        "model": "Lorem Ipsum Lightning",
        "provider": "Internal Testing",
        "note": "Internal Testing",
        "providerUrl": "Internal Testing",
        "parameters": "# Gibberish for Testing.",
        "apiKey": "none"
    },
    {
        "model": "Lorem Ipsum Fast",
        "provider": "Internal Testing",
        "note": "Internal Testing",
        "providerUrl": "Internal Testing",
        "parameters": "# Gibberish for Testing.",
        "apiKey": "none"
    },
    {
        "model": "Lorem Ipsum Standard",
        "provider": "Internal Testing",
        "note": "Internal Testing",
        "providerUrl": "Internal Testing",
        "parameters": "# Gibberish for Testing.",
        "apiKey": "none"
    },
    {
        "model": "Local Model",
        "provider": "LM Studio",
        "note": "",
        "providerUrl": "http://localhost:1234/v1",
        "parameters": "#timeout           = float\n#frequency_penalty = float\n#logprobs          = bool\n#max_tokens        = int\n#n                 = int\n#presence_penalty  = float\n#seed              = int\n#stop              = text\n#temperature       = float\n#top_logprobs      = int\n#top_p             = float\n#user              = text",
        "apiKey": "none"
    },
    {
        "model": "",
        "provider": "Hugging Face Free",
        "note": "Non-Streaming Serverless Inference API",
        "providerUrl": "https://api-inference.huggingface.co/models/",
        "parameters": "max_time            = 60\ndo_sample           = True\n#top_k              = int\n#top_p              = int\n#temperature        = float\n#repetition_penalty = float\n#max_new_tokens     = int",
        "apiKey": ""
    }
]